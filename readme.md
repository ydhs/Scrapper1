# Scraper1

**Scraper1** — это простой проект для сбора, хранения и визуализации данных о текущей и прогнозной температуре в указанных городах.

---

## Содержание

1. [Функции](#функции)
2. [Структура проекта](#структура-проекта)
3. [Установка](#установка)
4. [Настройка](#настройка)
5. [Запуск](#запуск)
6. [Визуализация](#визуализация)
7. [Структура базы данных](#структура-базы-данных)
8. [Зависимости](#зависимости)

---

## Функции

- `main.py` — инициализация базы данных и сбор данных:
  - читает список городов из `settings.json`
  - парсит текущую температуру и прогноз на завтра (Selenium + BeautifulSoup)
  - сохраняет результаты в SQLite (`weather.db`)
- `parser.py` — реализация логики парсинга страниц Gismeteo:
  - извлечение текущей и прогнозной температуры
- `db.py` — работа с базой данных:
  - создание таблиц при первом запуске
  - добавление и очистка записей
- `analize.py` — визуализация данных за любую дату:
  - принимает дату в формате `dd.mm.YYYY`
  - строит графики текущей и прогнозной температуры
- `api.py` — REST API доступ к температурным данным
- `webapi.html` — простая HTML-страница, взаимодействующая с API через браузер

---

## Структура проекта

```
Scraper1/
├── main.py            # Сбор данных и запись в БД
├── parser.py          # Парсинг HTML-страниц Gismeteo
├── db.py              # Модуль работы с SQLite
├── analize.py         # Визуализация температур за дату
├── settings.json      # Список городов и URL-адреса
├── weather.db         # Файл базы данных (создаётся автоматически)
├── app.py             # Запуск Flask-приложения с API
├── api.py             # Реализация API
├── webapi.html        # Веб-интерфейс для запросов к API
└── requirements.txt   # Зависимости проекта
```

---

## Установка

1. Склонируйте репозиторий:
   ```bash
   git clone https://github.com/ydhs/Scrapper1.git
   cd Scrapper1
   ```

2. Создайте виртуальное окружение и активируйте его:
   ```bash
   python -m venv .venv
   .\.venv\Scripts\Activate.ps1  # Windows
   source .venv/bin/activate     # Linux/macOS
   ```

3. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```

---

## Настройка

Отредактируйте файл `settings.json`, указав список городов и соответствующие URL для текущей и прогнозной температур:

```json
{
  "cities": [
    {
      "name": "Новосибирск",
      "current_url": "https://...",
      "forecast_url": "https://..."
    }
  ]
}
```

---

## Запуск

1. **Сбор данных**:
   ```bash
   python main.py
   ```

2. **Визуализация**:
   ```bash
   python analize.py 22.05.2025
   ```

3. **Запуск API-сервера**:
   ```bash
   python app.py
   ```

   После запуска доступен API по адресу `http://127.0.0.1:5000/api/...`

   Примеры:

   - Последняя температура:
     `http://127.0.0.1:5000/api/temperature?city=Новосибирск`

   - Прогноз на день с сортировкой:
     `http://127.0.0.1:5000/api/forecast?city=Новосибирск&day=22.05.2025&sort=desc`

4. **Работа с веб-интерфейсом**:

   Откройте файл `webapi.html` в браузере.

   Это простая HTML-страница, позволяющая отправлять запросы к API через форму и отображать результат в браузере. Flask-приложение должно быть запущено.

---

## Структура базы данных

Используется SQLite-файл `weather.db` с тремя таблицами:

- `cities`:
  - `id` (INTEGER, PK) — идентификатор города
  - `name` (TEXT) — название города
  - `url` (TEXT) — базовый URL для парсинга
- `current_temperature`:
  - `id` (INTEGER, PK)
  - `city_id` (INTEGER)
  - `temperature` (REAL)
  - `timestamp` (TEXT)
- `forecast_temperature`:
  - `id` (INTEGER, PK)
  - `city_id` (INTEGER)
  - `temperature` (REAL)
  - `timestamp` (TEXT)

---

## Зависимости

- Python ≥3.x
- `selenium`
- `beautifulsoup4`
- `pandas`
- `matplotlib`
- `flask`
- `flask-cors`
- `requests`